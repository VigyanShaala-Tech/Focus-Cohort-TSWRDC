{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "3b78ad1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment file names associated with the DataFrames:\n",
      "data1 is associated with file: Assignment_Assignment_CAP Classwork.csv\n",
      "data2 is associated with file: Assignment_Assignment_CV_ Resume.csv\n",
      "data3 is associated with file: Assignment_Assignment_Full CAP - GoalA+B.csv\n",
      "data4 is associated with file: Assignment_Assignment_Long term dreams and short term goals.csv\n",
      "data5 is associated with file: Assignment_Assignment_Practice.csv\n",
      "data6 is associated with file: Assignment_Assignment_Preparing for PG_Masters.csv\n",
      "data7 is associated with file: Assignment_Assignment_SMART goal.csv\n",
      "data8 is associated with file: Assignment_Assignment_SWOT.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = r'C:/Users/User/Desktop/TSWRDC Code/Web Scraping/Source'   # Give your folder path here\n",
    "files = os.listdir(folder_path)\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "dataframes_list = []  # List to store the extracted DataFrames\n",
    "assignment_files_map = {}  # Dictionary to store the mapping of assignment file names with DataFrame variables\n",
    "dataframe_names = []  # List to store the names of the assigned DataFrames\n",
    "\n",
    "for i, file in enumerate(csv_files, 1):\n",
    "    file_path = os.path.join(folder_path, file) \n",
    "    df = pd.read_csv(file_path)\n",
    "    dataframe_name = f'data{i}'  # Variable name assigned to the DataFrame\n",
    "    globals()[dataframe_name] = df  # Assign each DataFrame to variables data1, data2, data3, and so on\n",
    "    dataframes_list.append(df)  \n",
    "    dataframe_names.append(dataframe_name)  # Append the assigned DataFrame name to the list\n",
    "    assignment_files_map[dataframe_name] = file  # Map assignment file names with DataFrame variables\n",
    "\n",
    "# Print out the assignment file names associated with the DataFrames\n",
    "print(\"Assignment file names associated with the DataFrames:\")\n",
    "for dataframe_var, file_name in assignment_files_map.items():\n",
    "    print(f\"{dataframe_var} is associated with file: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "b797016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data1': 'Assignment_Assignment_CAP Classwork.csv',\n",
       " 'data2': 'Assignment_Assignment_CV_ Resume.csv',\n",
       " 'data3': 'Assignment_Assignment_Full CAP - GoalA+B.csv',\n",
       " 'data4': 'Assignment_Assignment_Long term dreams and short term goals.csv',\n",
       " 'data5': 'Assignment_Assignment_Practice.csv',\n",
       " 'data6': 'Assignment_Assignment_Preparing for PG_Masters.csv',\n",
       " 'data7': 'Assignment_Assignment_SMART goal.csv',\n",
       " 'data8': 'Assignment_Assignment_SWOT.csv'}"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment_files_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "ac0b3a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Assignment_Assignment_CAP Classwork.csv', 'Assignment_Assignment_CV_ Resume.csv', 'Assignment_Assignment_Full CAP - GoalA+B.csv', 'Assignment_Assignment_Long term dreams and short term goals.csv', 'Assignment_Assignment_Practice.csv', 'Assignment_Assignment_Preparing for PG_Masters.csv', 'Assignment_Assignment_SMART goal.csv', 'Assignment_Assignment_SWOT.csv']\n"
     ]
    }
   ],
   "source": [
    "a=assignment_files_map.values()\n",
    "b=list(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "id": "c86cbaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data1', 'data2', 'data3', 'data4', 'data5', 'data6', 'data7', 'data8']"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "id": "bc8062a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>courseId</th>\n",
       "      <th>userId</th>\n",
       "      <th>status</th>\n",
       "      <th>data/0/date/date</th>\n",
       "      <th>data/0/date/day</th>\n",
       "      <th>data/0/date/hours</th>\n",
       "      <th>data/0/date/minutes</th>\n",
       "      <th>data/0/date/month</th>\n",
       "      <th>data/0/date/seconds</th>\n",
       "      <th>...</th>\n",
       "      <th>data/3/date/month</th>\n",
       "      <th>data/3/date/seconds</th>\n",
       "      <th>data/3/date/time</th>\n",
       "      <th>data/3/date/timezoneOffset</th>\n",
       "      <th>data/3/date/year</th>\n",
       "      <th>data/3/date/$date</th>\n",
       "      <th>data/3/status</th>\n",
       "      <th>data/3/message</th>\n",
       "      <th>data/3/adminId</th>\n",
       "      <th>data/2/adminId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6603f06c6a1e4c30c9956db3</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>63b85b34e4b0500381f84d88</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6603dcbf4be4f543075f906f</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>63b85b38e4b0500381f84dc5</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66044352d049461ee1c54481</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>63b9b0d5e4b0f26f1e03107d</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6602f8bbf433100054982893</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>63b9b0d6e4b0f26f1e031091</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6602f7c1efe5b67abb714f7d</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>63b9b0dfe4b0f26f1e0310ff</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>6603b983d43333796b0b7a00</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>65f2a19b31aa072fdd19cb10</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>6603b6322e1b213e6ce2f9af</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>65f2a19c31aa072fdd19cb14</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>6603b4e3cbabb5030a537b74</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>65f2a19e31aa072fdd19cb18</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>6603b431361ef3527ebc349e</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>65f2a1a131aa072fdd19cb20</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>66041b0c39348203474ca8e8</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>65fbe0e7008fd027464d4515</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id                  courseId  \\\n",
       "0    6603f06c6a1e4c30c9956db3  65c5d287e4b0bea88872e63b   \n",
       "1    6603dcbf4be4f543075f906f  65c5d287e4b0bea88872e63b   \n",
       "2    66044352d049461ee1c54481  65c5d287e4b0bea88872e63b   \n",
       "3    6602f8bbf433100054982893  65c5d287e4b0bea88872e63b   \n",
       "4    6602f7c1efe5b67abb714f7d  65c5d287e4b0bea88872e63b   \n",
       "..                        ...                       ...   \n",
       "760  6603b983d43333796b0b7a00  65c5d287e4b0bea88872e63b   \n",
       "761  6603b6322e1b213e6ce2f9af  65c5d287e4b0bea88872e63b   \n",
       "762  6603b4e3cbabb5030a537b74  65c5d287e4b0bea88872e63b   \n",
       "763  6603b431361ef3527ebc349e  65c5d287e4b0bea88872e63b   \n",
       "764  66041b0c39348203474ca8e8  65c5d287e4b0bea88872e63b   \n",
       "\n",
       "                       userId    status  data/0/date/date  data/0/date/day  \\\n",
       "0    63b85b34e4b0500381f84d88  reviewed                27                3   \n",
       "1    63b85b38e4b0500381f84dc5  reviewed                27                3   \n",
       "2    63b9b0d5e4b0f26f1e03107d  reviewed                27                3   \n",
       "3    63b9b0d6e4b0f26f1e031091  reviewed                26                2   \n",
       "4    63b9b0dfe4b0f26f1e0310ff  reviewed                26                2   \n",
       "..                        ...       ...               ...              ...   \n",
       "760  65f2a19b31aa072fdd19cb10  reviewed                27                3   \n",
       "761  65f2a19c31aa072fdd19cb14  reviewed                27                3   \n",
       "762  65f2a19e31aa072fdd19cb18  reviewed                27                3   \n",
       "763  65f2a1a131aa072fdd19cb20  reviewed                27                3   \n",
       "764  65fbe0e7008fd027464d4515  reviewed                27                3   \n",
       "\n",
       "     data/0/date/hours  data/0/date/minutes  data/0/date/month  \\\n",
       "0                   10                    9                  2   \n",
       "1                    8                   45                  2   \n",
       "2                   16                    3                  2   \n",
       "3                   16                   32                  2   \n",
       "4                   16                   28                  2   \n",
       "..                 ...                  ...                ...   \n",
       "760                  6                   15                  2   \n",
       "761                  6                    1                  2   \n",
       "762                  5                   55                  2   \n",
       "763                  5                   52                  2   \n",
       "764                 13                   11                  2   \n",
       "\n",
       "     data/0/date/seconds  ...  data/3/date/month  data/3/date/seconds  \\\n",
       "0                     48  ...                NaN                  NaN   \n",
       "1                     51  ...                NaN                  NaN   \n",
       "2                     30  ...                NaN                  NaN   \n",
       "3                     59  ...                NaN                  NaN   \n",
       "4                     49  ...                NaN                  NaN   \n",
       "..                   ...  ...                ...                  ...   \n",
       "760                   31  ...                NaN                  NaN   \n",
       "761                   22  ...                NaN                  NaN   \n",
       "762                   47  ...                NaN                  NaN   \n",
       "763                   49  ...                NaN                  NaN   \n",
       "764                   40  ...                NaN                  NaN   \n",
       "\n",
       "     data/3/date/time data/3/date/timezoneOffset data/3/date/year  \\\n",
       "0                 NaN                        NaN              NaN   \n",
       "1                 NaN                        NaN              NaN   \n",
       "2                 NaN                        NaN              NaN   \n",
       "3                 NaN                        NaN              NaN   \n",
       "4                 NaN                        NaN              NaN   \n",
       "..                ...                        ...              ...   \n",
       "760               NaN                        NaN              NaN   \n",
       "761               NaN                        NaN              NaN   \n",
       "762               NaN                        NaN              NaN   \n",
       "763               NaN                        NaN              NaN   \n",
       "764               NaN                        NaN              NaN   \n",
       "\n",
       "    data/3/date/$date  data/3/status data/3/message data/3/adminId  \\\n",
       "0                 NaN            NaN            NaN            NaN   \n",
       "1                 NaN            NaN            NaN            NaN   \n",
       "2                 NaN            NaN            NaN            NaN   \n",
       "3                 NaN            NaN            NaN            NaN   \n",
       "4                 NaN            NaN            NaN            NaN   \n",
       "..                ...            ...            ...            ...   \n",
       "760               NaN            NaN            NaN            NaN   \n",
       "761               NaN            NaN            NaN            NaN   \n",
       "762               NaN            NaN            NaN            NaN   \n",
       "763               NaN            NaN            NaN            NaN   \n",
       "764               NaN            NaN            NaN            NaN   \n",
       "\n",
       "     data/2/adminId  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "..              ...  \n",
       "760             NaN  \n",
       "761             NaN  \n",
       "762             NaN  \n",
       "763             NaN  \n",
       "764             NaN  \n",
       "\n",
       "[765 rows x 67 columns]"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "09481f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "6435481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Put the names that are present in the dataframe_names varaible above manually here in final_data list in\n",
    "##accordance to the name present number of file name ###\n",
    "################################################################################################################################\n",
    "\n",
    "final_data = [data1,data2,data3,data4,data5,data6,data7,data8]  # List of different assignment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "5b9c6ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of columns containing the date format in data file 1: 4\n",
      "Count of columns containing the date format in data file 2: 8\n",
      "Count of columns containing the date format in data file 3: 8\n",
      "Count of columns containing the date format in data file 4: 9\n",
      "Count of columns containing the date format in data file 5: 4\n",
      "Count of columns containing the date format in data file 6: 6\n",
      "Count of columns containing the date format in data file 7: 10\n",
      "Count of columns containing the date format in data file 8: 8\n"
     ]
    }
   ],
   "source": [
    "###Put the names that are present in the dataframe_names manually here in accordance to the name present number of file name ###\n",
    "################################################################################################################################\n",
    "\n",
    "num_date_columns_list = []  # List to store the count of date columns for each file\n",
    "\n",
    "for data_file in final_data:\n",
    "    data = {}\n",
    "    date_column_count = 0\n",
    "\n",
    "    for key, value in data_file.items():\n",
    "        if key.startswith('data/') and key.endswith('/date/$date'):\n",
    "            data[key] = value\n",
    "            date_column_count += 1\n",
    "\n",
    "    num_date_columns_list.append(date_column_count)\n",
    "\n",
    "# Print the count of date columns for each data file\n",
    "for i, count in enumerate(num_date_columns_list, start=1):\n",
    "    print(f\"Count of columns containing the date format in data file {i}: {count}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a60e0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "b4e940d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = final_data\n",
    "data_list = [{}, {}, {}, {},{},{},{},{}]   #Add the number of {} in accordance with the number of data files that are \n",
    "                                              #imported that are mentioned in the data_frames names.\n",
    "# Replace with the actual num_date_columns_list\n",
    "num_date_columns_list = num_date_columns_list  \n",
    "\n",
    "# Iterate through each DataFrame and extract the data into separate dictionaries using a loop\n",
    "for i, (df, data, num_date_columns) in enumerate(zip(dataframes, data_list, num_date_columns_list), start=1):\n",
    "    # Clear the dictionary before adding new data\n",
    "    data.clear()  \n",
    "    num_date_columns = num_date_columns \n",
    "    # Clear the dictionary before adding new data\n",
    "    data = {}  \n",
    "    for j in range(num_date_columns):\n",
    "        key = f'mixed_date{j+1}'\n",
    "        data[key] = df[f'data/{j}/date/$date']\n",
    "        \n",
    "        \n",
    "    # Update the data list with the extracted data dictionary for the respective DataFrame\n",
    "    data_list[i-1] = data  \n",
    "\n",
    "# Now, data_list[0], data_list[1], data_list[2], data_list[3], data_list[4], data_list[5], and data_list[6] will contain the extracted data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "b7b6fed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "90bd948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4\n",
      "0  2024-03-27T10:09:48.337Z  2024-03-27T10:37:01.703Z         NaN         NaN\n",
      "1  2024-03-27T08:45:51.555Z  2024-03-27T09:45:58.771Z         NaN         NaN\n",
      "2  2024-03-27T16:03:30.097Z  2024-03-27T19:34:11.540Z         NaN         NaN\n",
      "3  2024-03-26T16:32:59.768Z  2024-03-26T17:20:09.418Z         NaN         NaN\n",
      "4  2024-03-26T16:28:49.581Z  2024-03-26T17:20:35.328Z         NaN         NaN\n",
      "\n",
      "\n",
      "DataFrame 2:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4  \\\n",
      "0  2024-04-15T07:26:52.908Z  2024-04-16T11:12:11.965Z         NaN         NaN   \n",
      "1  2024-04-15T09:21:03.916Z                       NaN         NaN         NaN   \n",
      "2  2024-04-09T14:53:22.595Z                       NaN         NaN         NaN   \n",
      "3  2024-04-17T09:37:04.979Z                       NaN         NaN         NaN   \n",
      "4  2024-04-17T09:14:36.791Z                       NaN         NaN         NaN   \n",
      "\n",
      "  mixed_date5 mixed_date6 mixed_date7 mixed_date8  \n",
      "0         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN  \n",
      "\n",
      "\n",
      "DataFrame 3:\n",
      "                mixed_date1 mixed_date2 mixed_date3 mixed_date4 mixed_date5  \\\n",
      "0  2024-04-14T14:59:29.493Z         NaN         NaN         NaN         NaN   \n",
      "1  2024-04-14T05:06:31.934Z         NaN         NaN         NaN         NaN   \n",
      "2  2024-04-14T16:47:00.504Z         NaN         NaN         NaN         NaN   \n",
      "3  2024-04-14T09:42:12.835Z         NaN         NaN         NaN         NaN   \n",
      "4  2024-04-13T17:50:33.949Z         NaN         NaN         NaN         NaN   \n",
      "\n",
      "  mixed_date6 mixed_date7 mixed_date8  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "\n",
      "DataFrame 4:\n",
      "                mixed_date1               mixed_date2  \\\n",
      "0  2024-03-04T15:05:39.601Z  2024-03-10T18:54:18.922Z   \n",
      "1  2024-03-14T12:58:40.083Z  2024-03-18T05:59:34.800Z   \n",
      "2  2024-03-03T12:31:31.775Z  2024-03-10T18:55:10.790Z   \n",
      "3  2024-03-01T15:28:00.494Z  2024-03-10T18:55:36.277Z   \n",
      "4  2024-03-07T04:08:27.491Z  2024-03-10T18:56:45.252Z   \n",
      "\n",
      "                mixed_date3               mixed_date4 mixed_date5 mixed_date6  \\\n",
      "0  2024-03-11T15:49:02.077Z  2024-03-13T06:49:58.501Z         NaN         NaN   \n",
      "1                       NaN                       NaN         NaN         NaN   \n",
      "2                       NaN                       NaN         NaN         NaN   \n",
      "3                       NaN                       NaN         NaN         NaN   \n",
      "4                       NaN                       NaN         NaN         NaN   \n",
      "\n",
      "  mixed_date7 mixed_date8 mixed_date9  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "\n",
      "DataFrame 5:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4\n",
      "0  2024-02-23T07:04:09.862Z  2024-03-01T10:11:36.690Z         NaN         NaN\n",
      "1  2024-02-23T07:03:42.872Z  2024-03-01T10:11:24.567Z         NaN         NaN\n",
      "2  2024-02-26T12:02:03.859Z  2024-03-01T10:14:18.058Z         NaN         NaN\n",
      "3  2024-02-23T07:51:09.621Z  2024-03-01T10:13:34.415Z         NaN         NaN\n",
      "4  2024-02-23T06:55:58.962Z  2024-03-01T10:10:47.540Z         NaN         NaN\n",
      "\n",
      "\n",
      "DataFrame 6:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4  \\\n",
      "0  2024-03-25T14:51:13.785Z  2024-03-28T09:54:11.782Z         NaN         NaN   \n",
      "1  2024-03-25T06:49:51.123Z  2024-03-28T09:55:19.122Z         NaN         NaN   \n",
      "2  2024-03-17T15:22:00.006Z  2024-03-20T10:06:50.588Z         NaN         NaN   \n",
      "3  2024-03-18T03:12:45.888Z  2024-03-20T10:07:25.279Z         NaN         NaN   \n",
      "4  2024-03-25T09:57:15.986Z  2024-03-28T09:55:52.234Z         NaN         NaN   \n",
      "\n",
      "  mixed_date5 mixed_date6  \n",
      "0         NaN         NaN  \n",
      "1         NaN         NaN  \n",
      "2         NaN         NaN  \n",
      "3         NaN         NaN  \n",
      "4         NaN         NaN  \n",
      "\n",
      "\n",
      "DataFrame 7:\n",
      "                mixed_date1               mixed_date2  \\\n",
      "0  2024-03-04T15:06:02.389Z  2024-03-09T20:37:32.318Z   \n",
      "1  2024-03-14T12:59:27.433Z  2024-03-18T09:27:13.068Z   \n",
      "2  2024-03-03T12:31:40.937Z  2024-03-09T20:36:05.325Z   \n",
      "3  2024-03-01T15:28:13.167Z  2024-03-09T20:39:32.700Z   \n",
      "4  2024-03-07T04:08:53.158Z  2024-03-09T20:36:29.958Z   \n",
      "\n",
      "                mixed_date3               mixed_date4 mixed_date5 mixed_date6  \\\n",
      "0  2024-03-12T15:49:18.436Z  2024-04-01T12:49:47.541Z         NaN         NaN   \n",
      "1                       NaN                       NaN         NaN         NaN   \n",
      "2  2024-03-12T16:25:09.301Z  2024-04-01T12:48:46.955Z         NaN         NaN   \n",
      "3  2024-03-12T16:21:03.779Z  2024-04-01T12:55:43.890Z         NaN         NaN   \n",
      "4                       NaN                       NaN         NaN         NaN   \n",
      "\n",
      "  mixed_date7 mixed_date8 mixed_date9 mixed_date10  \n",
      "0         NaN         NaN         NaN          NaN  \n",
      "1         NaN         NaN         NaN          NaN  \n",
      "2         NaN         NaN         NaN          NaN  \n",
      "3         NaN         NaN         NaN          NaN  \n",
      "4         NaN         NaN         NaN          NaN  \n",
      "\n",
      "\n",
      "DataFrame 8:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4  \\\n",
      "0  2024-03-24T16:32:53.476Z  2024-04-01T09:58:13.265Z         NaN         NaN   \n",
      "1  2024-03-14T16:12:08.396Z  2024-04-01T09:59:54.729Z         NaN         NaN   \n",
      "2  2024-03-14T12:03:10.092Z  2024-04-01T10:00:55.155Z         NaN         NaN   \n",
      "3  2024-03-12T16:25:31.676Z  2024-03-15T07:05:43.947Z         NaN         NaN   \n",
      "4  2024-03-12T16:19:54.229Z  2024-04-01T10:00:20.062Z         NaN         NaN   \n",
      "\n",
      "  mixed_date5 mixed_date6 mixed_date7 mixed_date8  \n",
      "0         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through the data_list to create DataFrames\n",
    "for i in range(len(dataframe_names)):\n",
    "    # Create DataFrame from each data dictionary\n",
    "    df = pd.DataFrame(data_list[i])\n",
    "    # Append the created DataFrame to the list\n",
    "    dataframes.append(df)  \n",
    "\n",
    "# Print the DataFrames to verify\n",
    "for i, df in enumerate(dataframes, start=1):\n",
    "    print(f\"DataFrame {i}:\")\n",
    "    print(df.head())\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "4f883385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Submission for DataFrame 1:\n",
      "0   2024-03-27 10:37:01.703000+00:00\n",
      "1   2024-03-27 09:45:58.771000+00:00\n",
      "2   2024-03-27 19:34:11.540000+00:00\n",
      "3   2024-03-26 17:20:09.418000+00:00\n",
      "4   2024-03-26 17:20:35.328000+00:00\n",
      "Name: Latest_Submission, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Latest Submission for DataFrame 2:\n",
      "0   2024-04-16 11:12:11.965000+00:00\n",
      "1   2024-04-15 09:21:03.916000+00:00\n",
      "2   2024-04-09 14:53:22.595000+00:00\n",
      "3   2024-04-17 09:37:04.979000+00:00\n",
      "4   2024-04-17 09:14:36.791000+00:00\n",
      "Name: Latest_Submission, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Latest Submission for DataFrame 3:\n",
      "0   2024-04-14 14:59:29.493000+00:00\n",
      "1   2024-04-14 05:06:31.934000+00:00\n",
      "2   2024-04-14 16:47:00.504000+00:00\n",
      "3   2024-04-14 09:42:12.835000+00:00\n",
      "4   2024-04-13 17:50:33.949000+00:00\n",
      "Name: Latest_Submission, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Latest Submission for DataFrame 4:\n",
      "0   2024-03-13 06:49:58.501000+00:00\n",
      "1   2024-03-18 05:59:34.800000+00:00\n",
      "2   2024-03-10 18:55:10.790000+00:00\n",
      "3   2024-03-10 18:55:36.277000+00:00\n",
      "4   2024-03-10 18:56:45.252000+00:00\n",
      "Name: Latest_Submission, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Latest Submission for DataFrame 5:\n",
      "0   2024-03-01 10:11:36.690000+00:00\n",
      "1   2024-03-01 10:11:24.567000+00:00\n",
      "2   2024-03-01 10:14:18.058000+00:00\n",
      "3   2024-03-01 10:13:34.415000+00:00\n",
      "4   2024-03-01 10:10:47.540000+00:00\n",
      "Name: Latest_Submission, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Latest Submission for DataFrame 6:\n",
      "0   2024-03-28 09:54:11.782000+00:00\n",
      "1   2024-03-28 09:55:19.122000+00:00\n",
      "2   2024-03-20 10:06:50.588000+00:00\n",
      "3   2024-03-20 10:07:25.279000+00:00\n",
      "4   2024-03-28 09:55:52.234000+00:00\n",
      "Name: Latest_Submission, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Latest Submission for DataFrame 7:\n",
      "0   2024-04-01 12:49:47.541000+00:00\n",
      "1   2024-03-18 09:27:13.068000+00:00\n",
      "2   2024-04-01 12:48:46.955000+00:00\n",
      "3   2024-04-01 12:55:43.890000+00:00\n",
      "4   2024-03-09 20:36:29.958000+00:00\n",
      "Name: Latest_Submission, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Latest Submission for DataFrame 8:\n",
      "0   2024-04-01 09:58:13.265000+00:00\n",
      "1   2024-04-01 09:59:54.729000+00:00\n",
      "2   2024-04-01 10:00:55.155000+00:00\n",
      "3   2024-03-15 07:05:43.947000+00:00\n",
      "4   2024-04-01 10:00:20.062000+00:00\n",
      "Name: Latest_Submission, dtype: datetime64[ns, UTC]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each DataFrame in the list and convert the mixed format date columns to datetime objects\n",
    "for df in dataframes:\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        \n",
    "# Iterate through each DataFrame in the list and perform the specified operation\n",
    "for i, df in enumerate(dataframes, start=1):\n",
    "    df['Latest_Submission'] = df.max(axis=1, skipna=True)\n",
    "    print(f\"Latest Submission for DataFrame {i}:\\n{df['Latest_Submission'].head()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "b1487415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Submission Dates for DataFrame 1:\n",
      "0   2024-03-27 10:09:48.337000+00:00\n",
      "1   2024-03-27 08:45:51.555000+00:00\n",
      "2   2024-03-27 16:03:30.097000+00:00\n",
      "3   2024-03-26 16:32:59.768000+00:00\n",
      "4   2024-03-26 16:28:49.581000+00:00\n",
      "Name: Previous_Submission_Date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Previous Submission Dates for DataFrame 2:\n",
      "0   2024-04-15 07:26:52.908000+00:00\n",
      "1   2024-04-15 09:21:03.916000+00:00\n",
      "2   2024-04-09 14:53:22.595000+00:00\n",
      "3   2024-04-17 09:37:04.979000+00:00\n",
      "4   2024-04-17 09:14:36.791000+00:00\n",
      "Name: Previous_Submission_Date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Previous Submission Dates for DataFrame 3:\n",
      "0   2024-04-14 14:59:29.493000+00:00\n",
      "1   2024-04-14 05:06:31.934000+00:00\n",
      "2   2024-04-14 16:47:00.504000+00:00\n",
      "3   2024-04-14 09:42:12.835000+00:00\n",
      "4   2024-04-13 17:50:33.949000+00:00\n",
      "Name: Previous_Submission_Date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Previous Submission Dates for DataFrame 4:\n",
      "0   2024-03-11 15:49:02.077000+00:00\n",
      "1   2024-03-14 12:58:40.083000+00:00\n",
      "2   2024-03-03 12:31:31.775000+00:00\n",
      "3   2024-03-01 15:28:00.494000+00:00\n",
      "4   2024-03-07 04:08:27.491000+00:00\n",
      "Name: Previous_Submission_Date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Previous Submission Dates for DataFrame 5:\n",
      "0   2024-02-23 07:04:09.862000+00:00\n",
      "1   2024-02-23 07:03:42.872000+00:00\n",
      "2   2024-02-26 12:02:03.859000+00:00\n",
      "3   2024-02-23 07:51:09.621000+00:00\n",
      "4   2024-02-23 06:55:58.962000+00:00\n",
      "Name: Previous_Submission_Date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Previous Submission Dates for DataFrame 6:\n",
      "0   2024-03-25 14:51:13.785000+00:00\n",
      "1   2024-03-25 06:49:51.123000+00:00\n",
      "2   2024-03-17 15:22:00.006000+00:00\n",
      "3   2024-03-18 03:12:45.888000+00:00\n",
      "4   2024-03-25 09:57:15.986000+00:00\n",
      "Name: Previous_Submission_Date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Previous Submission Dates for DataFrame 7:\n",
      "0   2024-03-12 15:49:18.436000+00:00\n",
      "1   2024-03-14 12:59:27.433000+00:00\n",
      "2   2024-03-12 16:25:09.301000+00:00\n",
      "3   2024-03-12 16:21:03.779000+00:00\n",
      "4   2024-03-07 04:08:53.158000+00:00\n",
      "Name: Previous_Submission_Date, dtype: datetime64[ns, UTC]\n",
      "\n",
      "Previous Submission Dates for DataFrame 8:\n",
      "0   2024-03-24 16:32:53.476000+00:00\n",
      "1   2024-03-14 16:12:08.396000+00:00\n",
      "2   2024-03-14 12:03:10.092000+00:00\n",
      "3   2024-03-12 16:25:31.676000+00:00\n",
      "4   2024-03-12 16:19:54.229000+00:00\n",
      "Name: Previous_Submission_Date, dtype: datetime64[ns, UTC]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_previous_date(row):\n",
    "    max_date_index = row.values.argmax()\n",
    "    previous_date = row.iloc[max_date_index - 2] if max_date_index > 0 else pd.NaT\n",
    "    return previous_date\n",
    "\n",
    "# Iterate through each DataFrame in the list and apply the get_previous_date function\n",
    "for i, df in enumerate(dataframes, start=1):\n",
    "    df['Previous_Submission_Date'] = df.apply(get_previous_date, axis=1)\n",
    "    print(f\"Previous Submission Dates for DataFrame {i}:\\n{df['Previous_Submission_Date'].head()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "feb94718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in Submission Dates for DataFrame 1:\n",
      "          Previous_Submission_Date                Latest_Submission  \\\n",
      "0 2024-03-27 10:09:48.337000+00:00 2024-03-27 10:37:01.703000+00:00   \n",
      "1 2024-03-27 08:45:51.555000+00:00 2024-03-27 09:45:58.771000+00:00   \n",
      "2 2024-03-27 16:03:30.097000+00:00 2024-03-27 19:34:11.540000+00:00   \n",
      "3 2024-03-26 16:32:59.768000+00:00 2024-03-26 17:20:09.418000+00:00   \n",
      "4 2024-03-26 16:28:49.581000+00:00 2024-03-26 17:20:35.328000+00:00   \n",
      "\n",
      "   Submission_Date_Difference  \n",
      "0                         0.0  \n",
      "1                         0.0  \n",
      "2                         0.0  \n",
      "3                         0.0  \n",
      "4                         0.0  \n",
      "\n",
      "Difference in Submission Dates for DataFrame 2:\n",
      "          Previous_Submission_Date                Latest_Submission  \\\n",
      "0 2024-04-15 07:26:52.908000+00:00 2024-04-16 11:12:11.965000+00:00   \n",
      "1 2024-04-15 09:21:03.916000+00:00 2024-04-15 09:21:03.916000+00:00   \n",
      "2 2024-04-09 14:53:22.595000+00:00 2024-04-09 14:53:22.595000+00:00   \n",
      "3 2024-04-17 09:37:04.979000+00:00 2024-04-17 09:37:04.979000+00:00   \n",
      "4 2024-04-17 09:14:36.791000+00:00 2024-04-17 09:14:36.791000+00:00   \n",
      "\n",
      "   Submission_Date_Difference  \n",
      "0                          24  \n",
      "1                           0  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           0  \n",
      "\n",
      "Difference in Submission Dates for DataFrame 3:\n",
      "          Previous_Submission_Date                Latest_Submission  \\\n",
      "0 2024-04-14 14:59:29.493000+00:00 2024-04-14 14:59:29.493000+00:00   \n",
      "1 2024-04-14 05:06:31.934000+00:00 2024-04-14 05:06:31.934000+00:00   \n",
      "2 2024-04-14 16:47:00.504000+00:00 2024-04-14 16:47:00.504000+00:00   \n",
      "3 2024-04-14 09:42:12.835000+00:00 2024-04-14 09:42:12.835000+00:00   \n",
      "4 2024-04-13 17:50:33.949000+00:00 2024-04-13 17:50:33.949000+00:00   \n",
      "\n",
      "   Submission_Date_Difference  \n",
      "0                           0  \n",
      "1                           0  \n",
      "2                           0  \n",
      "3                           0  \n",
      "4                           0  \n",
      "\n",
      "Difference in Submission Dates for DataFrame 4:\n",
      "          Previous_Submission_Date                Latest_Submission  \\\n",
      "0 2024-03-11 15:49:02.077000+00:00 2024-03-13 06:49:58.501000+00:00   \n",
      "1 2024-03-14 12:58:40.083000+00:00 2024-03-18 05:59:34.800000+00:00   \n",
      "2 2024-03-03 12:31:31.775000+00:00 2024-03-10 18:55:10.790000+00:00   \n",
      "3 2024-03-01 15:28:00.494000+00:00 2024-03-10 18:55:36.277000+00:00   \n",
      "4 2024-03-07 04:08:27.491000+00:00 2024-03-10 18:56:45.252000+00:00   \n",
      "\n",
      "   Submission_Date_Difference  \n",
      "0                        24.0  \n",
      "1                        72.0  \n",
      "2                       168.0  \n",
      "3                       216.0  \n",
      "4                        72.0  \n",
      "\n",
      "Difference in Submission Dates for DataFrame 5:\n",
      "          Previous_Submission_Date                Latest_Submission  \\\n",
      "0 2024-02-23 07:04:09.862000+00:00 2024-03-01 10:11:36.690000+00:00   \n",
      "1 2024-02-23 07:03:42.872000+00:00 2024-03-01 10:11:24.567000+00:00   \n",
      "2 2024-02-26 12:02:03.859000+00:00 2024-03-01 10:14:18.058000+00:00   \n",
      "3 2024-02-23 07:51:09.621000+00:00 2024-03-01 10:13:34.415000+00:00   \n",
      "4 2024-02-23 06:55:58.962000+00:00 2024-03-01 10:10:47.540000+00:00   \n",
      "\n",
      "   Submission_Date_Difference  \n",
      "0                         168  \n",
      "1                         168  \n",
      "2                          72  \n",
      "3                         168  \n",
      "4                         168  \n",
      "\n",
      "Difference in Submission Dates for DataFrame 6:\n",
      "          Previous_Submission_Date                Latest_Submission  \\\n",
      "0 2024-03-25 14:51:13.785000+00:00 2024-03-28 09:54:11.782000+00:00   \n",
      "1 2024-03-25 06:49:51.123000+00:00 2024-03-28 09:55:19.122000+00:00   \n",
      "2 2024-03-17 15:22:00.006000+00:00 2024-03-20 10:06:50.588000+00:00   \n",
      "3 2024-03-18 03:12:45.888000+00:00 2024-03-20 10:07:25.279000+00:00   \n",
      "4 2024-03-25 09:57:15.986000+00:00 2024-03-28 09:55:52.234000+00:00   \n",
      "\n",
      "   Submission_Date_Difference  \n",
      "0                          48  \n",
      "1                          72  \n",
      "2                          48  \n",
      "3                          48  \n",
      "4                          48  \n",
      "\n",
      "Difference in Submission Dates for DataFrame 7:\n",
      "          Previous_Submission_Date                Latest_Submission  \\\n",
      "0 2024-03-12 15:49:18.436000+00:00 2024-04-01 12:49:47.541000+00:00   \n",
      "1 2024-03-14 12:59:27.433000+00:00 2024-03-18 09:27:13.068000+00:00   \n",
      "2 2024-03-12 16:25:09.301000+00:00 2024-04-01 12:48:46.955000+00:00   \n",
      "3 2024-03-12 16:21:03.779000+00:00 2024-04-01 12:55:43.890000+00:00   \n",
      "4 2024-03-07 04:08:53.158000+00:00 2024-03-09 20:36:29.958000+00:00   \n",
      "\n",
      "   Submission_Date_Difference  \n",
      "0                       456.0  \n",
      "1                        72.0  \n",
      "2                       456.0  \n",
      "3                       456.0  \n",
      "4                        48.0  \n",
      "\n",
      "Difference in Submission Dates for DataFrame 8:\n",
      "          Previous_Submission_Date                Latest_Submission  \\\n",
      "0 2024-03-24 16:32:53.476000+00:00 2024-04-01 09:58:13.265000+00:00   \n",
      "1 2024-03-14 16:12:08.396000+00:00 2024-04-01 09:59:54.729000+00:00   \n",
      "2 2024-03-14 12:03:10.092000+00:00 2024-04-01 10:00:55.155000+00:00   \n",
      "3 2024-03-12 16:25:31.676000+00:00 2024-03-15 07:05:43.947000+00:00   \n",
      "4 2024-03-12 16:19:54.229000+00:00 2024-04-01 10:00:20.062000+00:00   \n",
      "\n",
      "   Submission_Date_Difference  \n",
      "0                       168.0  \n",
      "1                       408.0  \n",
      "2                       408.0  \n",
      "3                        48.0  \n",
      "4                       456.0  \n",
      "\n",
      "Overall Average Time Difference: 81.0 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the average time differences\n",
    "average_time_differences = []\n",
    "\n",
    "# Iterate through each DataFrame in the list\n",
    "for i, df in enumerate(dataframes, start=1):\n",
    "    # Calculate the difference between the Latest Submission and Previous Submission Date \n",
    "    df['Submission_Date_Difference'] = ((df['Latest_Submission'] - df['Previous_Submission_Date']).dt.days * 24)\n",
    "    \n",
    "    # Calculate the average time difference\n",
    "    average_time_second_last = df['Submission_Date_Difference'].mean().round()\n",
    "    \n",
    "    # Append the average time difference to the list\n",
    "    average_time_differences.append(average_time_second_last)\n",
    "    \n",
    "    # Print the head of the DataFrame including the calculated difference\n",
    "    print(f\"Difference in Submission Dates for DataFrame {i}:\\n{df[['Previous_Submission_Date', 'Latest_Submission', 'Submission_Date_Difference']].head()}\\n\")\n",
    "\n",
    "# Calculate the average of all the average time differences\n",
    "overall_average_time_difference = (sum(average_time_differences) / len(average_time_differences)).round()\n",
    "print(f\"Overall Average Time Difference: {overall_average_time_difference} hours\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b3c48",
   "metadata": {},
   "source": [
    "Overall Average Time difference:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "4414d348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Average Time Difference: 81.0 hours\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall Average Time Difference: {overall_average_time_difference} hours\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a013a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e945196f",
   "metadata": {},
   "source": [
    "# Count Code of the daily updated Assignment Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "887632b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4\n",
      "0  2024-03-27T10:09:48.337Z  2024-03-27T10:37:01.703Z         NaN         NaN\n",
      "1  2024-03-27T08:45:51.555Z  2024-03-27T09:45:58.771Z         NaN         NaN\n",
      "2  2024-03-27T16:03:30.097Z  2024-03-27T19:34:11.540Z         NaN         NaN\n",
      "3  2024-03-26T16:32:59.768Z  2024-03-26T17:20:09.418Z         NaN         NaN\n",
      "4  2024-03-26T16:28:49.581Z  2024-03-26T17:20:35.328Z         NaN         NaN\n",
      "\n",
      "\n",
      "DataFrame 2:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4  \\\n",
      "0  2024-04-15T07:26:52.908Z  2024-04-16T11:12:11.965Z         NaN         NaN   \n",
      "1  2024-04-15T09:21:03.916Z                       NaN         NaN         NaN   \n",
      "2  2024-04-09T14:53:22.595Z                       NaN         NaN         NaN   \n",
      "3  2024-04-17T09:37:04.979Z                       NaN         NaN         NaN   \n",
      "4  2024-04-17T09:14:36.791Z                       NaN         NaN         NaN   \n",
      "\n",
      "  mixed_date5 mixed_date6 mixed_date7 mixed_date8  \n",
      "0         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN  \n",
      "\n",
      "\n",
      "DataFrame 3:\n",
      "                mixed_date1 mixed_date2 mixed_date3 mixed_date4 mixed_date5  \\\n",
      "0  2024-04-14T14:59:29.493Z         NaN         NaN         NaN         NaN   \n",
      "1  2024-04-14T05:06:31.934Z         NaN         NaN         NaN         NaN   \n",
      "2  2024-04-14T16:47:00.504Z         NaN         NaN         NaN         NaN   \n",
      "3  2024-04-14T09:42:12.835Z         NaN         NaN         NaN         NaN   \n",
      "4  2024-04-13T17:50:33.949Z         NaN         NaN         NaN         NaN   \n",
      "\n",
      "  mixed_date6 mixed_date7 mixed_date8  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "\n",
      "DataFrame 4:\n",
      "                mixed_date1               mixed_date2  \\\n",
      "0  2024-03-04T15:05:39.601Z  2024-03-10T18:54:18.922Z   \n",
      "1  2024-03-14T12:58:40.083Z  2024-03-18T05:59:34.800Z   \n",
      "2  2024-03-03T12:31:31.775Z  2024-03-10T18:55:10.790Z   \n",
      "3  2024-03-01T15:28:00.494Z  2024-03-10T18:55:36.277Z   \n",
      "4  2024-03-07T04:08:27.491Z  2024-03-10T18:56:45.252Z   \n",
      "\n",
      "                mixed_date3               mixed_date4 mixed_date5 mixed_date6  \\\n",
      "0  2024-03-11T15:49:02.077Z  2024-03-13T06:49:58.501Z         NaN         NaN   \n",
      "1                       NaN                       NaN         NaN         NaN   \n",
      "2                       NaN                       NaN         NaN         NaN   \n",
      "3                       NaN                       NaN         NaN         NaN   \n",
      "4                       NaN                       NaN         NaN         NaN   \n",
      "\n",
      "  mixed_date7 mixed_date8 mixed_date9  \n",
      "0         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN  \n",
      "\n",
      "\n",
      "DataFrame 5:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4\n",
      "0  2024-02-23T07:04:09.862Z  2024-03-01T10:11:36.690Z         NaN         NaN\n",
      "1  2024-02-23T07:03:42.872Z  2024-03-01T10:11:24.567Z         NaN         NaN\n",
      "2  2024-02-26T12:02:03.859Z  2024-03-01T10:14:18.058Z         NaN         NaN\n",
      "3  2024-02-23T07:51:09.621Z  2024-03-01T10:13:34.415Z         NaN         NaN\n",
      "4  2024-02-23T06:55:58.962Z  2024-03-01T10:10:47.540Z         NaN         NaN\n",
      "\n",
      "\n",
      "DataFrame 6:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4  \\\n",
      "0  2024-03-25T14:51:13.785Z  2024-03-28T09:54:11.782Z         NaN         NaN   \n",
      "1  2024-03-25T06:49:51.123Z  2024-03-28T09:55:19.122Z         NaN         NaN   \n",
      "2  2024-03-17T15:22:00.006Z  2024-03-20T10:06:50.588Z         NaN         NaN   \n",
      "3  2024-03-18T03:12:45.888Z  2024-03-20T10:07:25.279Z         NaN         NaN   \n",
      "4  2024-03-25T09:57:15.986Z  2024-03-28T09:55:52.234Z         NaN         NaN   \n",
      "\n",
      "  mixed_date5 mixed_date6  \n",
      "0         NaN         NaN  \n",
      "1         NaN         NaN  \n",
      "2         NaN         NaN  \n",
      "3         NaN         NaN  \n",
      "4         NaN         NaN  \n",
      "\n",
      "\n",
      "DataFrame 7:\n",
      "                mixed_date1               mixed_date2  \\\n",
      "0  2024-03-04T15:06:02.389Z  2024-03-09T20:37:32.318Z   \n",
      "1  2024-03-14T12:59:27.433Z  2024-03-18T09:27:13.068Z   \n",
      "2  2024-03-03T12:31:40.937Z  2024-03-09T20:36:05.325Z   \n",
      "3  2024-03-01T15:28:13.167Z  2024-03-09T20:39:32.700Z   \n",
      "4  2024-03-07T04:08:53.158Z  2024-03-09T20:36:29.958Z   \n",
      "\n",
      "                mixed_date3               mixed_date4 mixed_date5 mixed_date6  \\\n",
      "0  2024-03-12T15:49:18.436Z  2024-04-01T12:49:47.541Z         NaN         NaN   \n",
      "1                       NaN                       NaN         NaN         NaN   \n",
      "2  2024-03-12T16:25:09.301Z  2024-04-01T12:48:46.955Z         NaN         NaN   \n",
      "3  2024-03-12T16:21:03.779Z  2024-04-01T12:55:43.890Z         NaN         NaN   \n",
      "4                       NaN                       NaN         NaN         NaN   \n",
      "\n",
      "  mixed_date7 mixed_date8 mixed_date9 mixed_date10  \n",
      "0         NaN         NaN         NaN          NaN  \n",
      "1         NaN         NaN         NaN          NaN  \n",
      "2         NaN         NaN         NaN          NaN  \n",
      "3         NaN         NaN         NaN          NaN  \n",
      "4         NaN         NaN         NaN          NaN  \n",
      "\n",
      "\n",
      "DataFrame 8:\n",
      "                mixed_date1               mixed_date2 mixed_date3 mixed_date4  \\\n",
      "0  2024-03-24T16:32:53.476Z  2024-04-01T09:58:13.265Z         NaN         NaN   \n",
      "1  2024-03-14T16:12:08.396Z  2024-04-01T09:59:54.729Z         NaN         NaN   \n",
      "2  2024-03-14T12:03:10.092Z  2024-04-01T10:00:55.155Z         NaN         NaN   \n",
      "3  2024-03-12T16:25:31.676Z  2024-03-15T07:05:43.947Z         NaN         NaN   \n",
      "4  2024-03-12T16:19:54.229Z  2024-04-01T10:00:20.062Z         NaN         NaN   \n",
      "\n",
      "  mixed_date5 mixed_date6 mixed_date7 mixed_date8  \n",
      "0         NaN         NaN         NaN         NaN  \n",
      "1         NaN         NaN         NaN         NaN  \n",
      "2         NaN         NaN         NaN         NaN  \n",
      "3         NaN         NaN         NaN         NaN  \n",
      "4         NaN         NaN         NaN         NaN  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Used the same code as above to extract the mixed date formats columns of the format 'data/{i}/date/$date'\n",
    "# Create an empty list to store the DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through the data_list to create DataFrames\n",
    "for i in range(len(dataframe_names)):  \n",
    "    df = pd.DataFrame(data_list[i])  \n",
    "    dataframes.append(df)  \n",
    "\n",
    "# Print the DataFrames to verify\n",
    "for i, df in enumerate(dataframes, start=1):\n",
    "    print(f\"DataFrame {i}:\")\n",
    "    print(df.head())\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "85874fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Submission for DataFrame 1:\n",
      "0    2024-03-27 10:37:01.703000+00:00\n",
      "1    2024-03-27 09:45:58.771000+00:00\n",
      "2    2024-03-27 19:34:11.540000+00:00\n",
      "3    2024-03-26 17:20:09.418000+00:00\n",
      "4    2024-03-26 17:20:35.328000+00:00\n",
      "Name: Latest_Submission, dtype: object\n",
      "\n",
      "Latest Submission for DataFrame 2:\n",
      "0    2024-04-16 11:12:11.965000+00:00\n",
      "1    2024-04-15 09:21:03.916000+00:00\n",
      "2    2024-04-09 14:53:22.595000+00:00\n",
      "3    2024-04-17 09:37:04.979000+00:00\n",
      "4    2024-04-17 09:14:36.791000+00:00\n",
      "Name: Latest_Submission, dtype: object\n",
      "\n",
      "Latest Submission for DataFrame 3:\n",
      "0    2024-04-14 14:59:29.493000+00:00\n",
      "1    2024-04-14 05:06:31.934000+00:00\n",
      "2    2024-04-14 16:47:00.504000+00:00\n",
      "3    2024-04-14 09:42:12.835000+00:00\n",
      "4    2024-04-13 17:50:33.949000+00:00\n",
      "Name: Latest_Submission, dtype: object\n",
      "\n",
      "Latest Submission for DataFrame 4:\n",
      "0    2024-03-13 06:49:58.501000+00:00\n",
      "1    2024-03-18 05:59:34.800000+00:00\n",
      "2    2024-03-10 18:55:10.790000+00:00\n",
      "3    2024-03-10 18:55:36.277000+00:00\n",
      "4    2024-03-10 18:56:45.252000+00:00\n",
      "Name: Latest_Submission, dtype: object\n",
      "\n",
      "Latest Submission for DataFrame 5:\n",
      "0    2024-03-01 10:11:36.690000+00:00\n",
      "1    2024-03-01 10:11:24.567000+00:00\n",
      "2    2024-03-01 10:14:18.058000+00:00\n",
      "3    2024-03-01 10:13:34.415000+00:00\n",
      "4    2024-03-01 10:10:47.540000+00:00\n",
      "Name: Latest_Submission, dtype: object\n",
      "\n",
      "Latest Submission for DataFrame 6:\n",
      "0    2024-03-28 09:54:11.782000+00:00\n",
      "1    2024-03-28 09:55:19.122000+00:00\n",
      "2    2024-03-20 10:06:50.588000+00:00\n",
      "3    2024-03-20 10:07:25.279000+00:00\n",
      "4    2024-03-28 09:55:52.234000+00:00\n",
      "Name: Latest_Submission, dtype: object\n",
      "\n",
      "Latest Submission for DataFrame 7:\n",
      "0    2024-04-01 12:49:47.541000+00:00\n",
      "1    2024-03-18 09:27:13.068000+00:00\n",
      "2    2024-04-01 12:48:46.955000+00:00\n",
      "3    2024-04-01 12:55:43.890000+00:00\n",
      "4    2024-03-09 20:36:29.958000+00:00\n",
      "Name: Latest_Submission, dtype: object\n",
      "\n",
      "Latest Submission for DataFrame 8:\n",
      "0    2024-04-01 09:58:13.265000+00:00\n",
      "1    2024-04-01 09:59:54.729000+00:00\n",
      "2    2024-04-01 10:00:55.155000+00:00\n",
      "3    2024-03-15 07:05:43.947000+00:00\n",
      "4    2024-04-01 10:00:20.062000+00:00\n",
      "Name: Latest_Submission, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Code to obtain the columns with latest submissions date i.e present in the latest updated column of the format 'data/{i}/date/$date' from the all the mixed data format column \n",
    "# Iterate through each DataFrame in the list and convert the mixed format date columns to datetime objects\n",
    "for df in dataframes:\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        \n",
    "# Iterate through each DataFrame in the list and perform the specified operation\n",
    "for i, df in enumerate(dataframes, start=1):\n",
    "    df['Latest_Submission'] = df.max(axis=1, skipna=True)\n",
    "    \n",
    "    # Convert the \"Latest Submission\" column to string datatype\n",
    "    df['Latest_Submission'] = df['Latest_Submission'].astype(str)\n",
    "    \n",
    "    print(f\"Latest Submission for DataFrame {i}:\\n{df['Latest_Submission'].head()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "95923c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Submission for DataFrame 1 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-03-27 10:37:01.703000+00:00              2024-03-27\n",
      "1  2024-03-27 09:45:58.771000+00:00              2024-03-27\n",
      "2  2024-03-27 19:34:11.540000+00:00              2024-03-27\n",
      "3  2024-03-26 17:20:09.418000+00:00              2024-03-26\n",
      "4  2024-03-26 17:20:35.328000+00:00              2024-03-26\n"
     ]
    }
   ],
   "source": [
    "# Specify the DataFrame index for DataFrame 1 (assuming it is the first DataFrame in the list)\n",
    "df_index = 0\n",
    "\n",
    "# Split the \"Latest Submission for DataFrame 1\" column rows containing datetime data after the first space\n",
    "dataframes[df_index]['Latest_Submission_split'] = dataframes[df_index]['Latest_Submission'].str.split(' ', n=1).str[0]\n",
    "\n",
    "# Print the modified DataFrame 1 with the split datetime data\n",
    "print(\"Latest Submission for DataFrame 1 with Datetime Data after First Space:\")\n",
    "print(dataframes[df_index][['Latest_Submission', 'Latest_Submission_split']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "3ad0bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Submission for DataFrame 1 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-03-27 10:37:01.703000+00:00              2024-03-27\n",
      "1  2024-03-27 09:45:58.771000+00:00              2024-03-27\n",
      "2  2024-03-27 19:34:11.540000+00:00              2024-03-27\n",
      "3  2024-03-26 17:20:09.418000+00:00              2024-03-26\n",
      "4  2024-03-26 17:20:35.328000+00:00              2024-03-26\n",
      "\n",
      "Latest Submission for DataFrame 2 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-04-16 11:12:11.965000+00:00              2024-04-16\n",
      "1  2024-04-15 09:21:03.916000+00:00              2024-04-15\n",
      "2  2024-04-09 14:53:22.595000+00:00              2024-04-09\n",
      "3  2024-04-17 09:37:04.979000+00:00              2024-04-17\n",
      "4  2024-04-17 09:14:36.791000+00:00              2024-04-17\n",
      "\n",
      "Latest Submission for DataFrame 3 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-04-14 14:59:29.493000+00:00              2024-04-14\n",
      "1  2024-04-14 05:06:31.934000+00:00              2024-04-14\n",
      "2  2024-04-14 16:47:00.504000+00:00              2024-04-14\n",
      "3  2024-04-14 09:42:12.835000+00:00              2024-04-14\n",
      "4  2024-04-13 17:50:33.949000+00:00              2024-04-13\n",
      "\n",
      "Latest Submission for DataFrame 4 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-03-13 06:49:58.501000+00:00              2024-03-13\n",
      "1  2024-03-18 05:59:34.800000+00:00              2024-03-18\n",
      "2  2024-03-10 18:55:10.790000+00:00              2024-03-10\n",
      "3  2024-03-10 18:55:36.277000+00:00              2024-03-10\n",
      "4  2024-03-10 18:56:45.252000+00:00              2024-03-10\n",
      "\n",
      "Latest Submission for DataFrame 5 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-03-01 10:11:36.690000+00:00              2024-03-01\n",
      "1  2024-03-01 10:11:24.567000+00:00              2024-03-01\n",
      "2  2024-03-01 10:14:18.058000+00:00              2024-03-01\n",
      "3  2024-03-01 10:13:34.415000+00:00              2024-03-01\n",
      "4  2024-03-01 10:10:47.540000+00:00              2024-03-01\n",
      "\n",
      "Latest Submission for DataFrame 6 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-03-28 09:54:11.782000+00:00              2024-03-28\n",
      "1  2024-03-28 09:55:19.122000+00:00              2024-03-28\n",
      "2  2024-03-20 10:06:50.588000+00:00              2024-03-20\n",
      "3  2024-03-20 10:07:25.279000+00:00              2024-03-20\n",
      "4  2024-03-28 09:55:52.234000+00:00              2024-03-28\n",
      "\n",
      "Latest Submission for DataFrame 7 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-04-01 12:49:47.541000+00:00              2024-04-01\n",
      "1  2024-03-18 09:27:13.068000+00:00              2024-03-18\n",
      "2  2024-04-01 12:48:46.955000+00:00              2024-04-01\n",
      "3  2024-04-01 12:55:43.890000+00:00              2024-04-01\n",
      "4  2024-03-09 20:36:29.958000+00:00              2024-03-09\n",
      "\n",
      "Latest Submission for DataFrame 8 with Datetime Data after First Space:\n",
      "                  Latest_Submission Latest_Submission_split\n",
      "0  2024-04-01 09:58:13.265000+00:00              2024-04-01\n",
      "1  2024-04-01 09:59:54.729000+00:00              2024-04-01\n",
      "2  2024-04-01 10:00:55.155000+00:00              2024-04-01\n",
      "3  2024-03-15 07:05:43.947000+00:00              2024-03-15\n",
      "4  2024-04-01 10:00:20.062000+00:00              2024-04-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each DataFrame in the list\n",
    "for i, df in enumerate(dataframes, start=1):\n",
    "    # Split the \"Latest Submission\" column rows containing datetime data after the first space\n",
    "    df['Latest_Submission_split'] = df['Latest_Submission'].str.split(' ', n=1).str[0]\n",
    "    \n",
    "    # Print the modified DataFrame with the split datetime data\n",
    "    print(f\"Latest Submission for DataFrame {i} with Datetime Data after First Space:\")\n",
    "    print(df[['Latest_Submission', 'Latest_Submission_split']].head())\n",
    "    print()  # Add a new line for better readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "5af75243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2024-04-16 11:12:11.965000+00:00\n",
       "1      2024-04-15 09:21:03.916000+00:00\n",
       "2      2024-04-09 14:53:22.595000+00:00\n",
       "3      2024-04-17 09:37:04.979000+00:00\n",
       "4      2024-04-17 09:14:36.791000+00:00\n",
       "                     ...               \n",
       "311    2024-03-21 04:48:51.648000+00:00\n",
       "312    2024-03-21 04:49:03.362000+00:00\n",
       "313    2024-03-21 04:49:10.851000+00:00\n",
       "314    2024-03-21 04:49:21.055000+00:00\n",
       "315    2024-03-21 04:51:14.493000+00:00\n",
       "Name: Latest_Submission, Length: 316, dtype: object"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1]['Latest_Submission']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "30a837d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2024-04-16\n",
       "1      2024-04-15\n",
       "2      2024-04-09\n",
       "3      2024-04-17\n",
       "4      2024-04-17\n",
       "          ...    \n",
       "311    2024-03-21\n",
       "312    2024-03-21\n",
       "313    2024-03-21\n",
       "314    2024-03-21\n",
       "315    2024-03-21\n",
       "Name: Latest_Submission_split, Length: 316, dtype: object"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1]['Latest_Submission_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "f74aa583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each DataFrame in the list\n",
    "for i, df in enumerate(final_data, start=1):\n",
    "    # Update the \"Latest Submission\" column in each DataFrame with the split data\n",
    "    df['Latest_Submission'] = dataframes[i-1]['Latest_Submission']\n",
    "    df['Latest_Submission_split'] = dataframes[i-1]['Latest_Submission_split']\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    new_file_path = f'updated_file_{i}.csv'  # Replace with the desired file naming convention\n",
    "    df.to_csv(new_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "fa4419d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>courseId</th>\n",
       "      <th>userId</th>\n",
       "      <th>status</th>\n",
       "      <th>data/0/date/date</th>\n",
       "      <th>data/0/date/day</th>\n",
       "      <th>data/0/date/hours</th>\n",
       "      <th>data/0/date/minutes</th>\n",
       "      <th>data/0/date/month</th>\n",
       "      <th>data/0/date/seconds</th>\n",
       "      <th>...</th>\n",
       "      <th>data/7/date/time</th>\n",
       "      <th>data/7/date/timezoneOffset</th>\n",
       "      <th>data/7/date/year</th>\n",
       "      <th>data/7/date/$date</th>\n",
       "      <th>data/7/status</th>\n",
       "      <th>data/7/message</th>\n",
       "      <th>data/7/adminId</th>\n",
       "      <th>data/4/notes</th>\n",
       "      <th>Latest_Submission</th>\n",
       "      <th>Latest_Submission_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>661cd6bcf179b74c0b33e51f</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>63b6dbd1e4b04d78f40b0ad0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-16 11:12:11.965000+00:00</td>\n",
       "      <td>2024-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>661cf17f350de60f684a7d62</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>63b6dbf1e4b04d78f40b0c00</td>\n",
       "      <td>under review</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-15 09:21:03.916000+00:00</td>\n",
       "      <td>2024-04-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6615566215d8d561ecaa108a</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>63b6dbf4e4b04d78f40b0c2e</td>\n",
       "      <td>under review</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-09 14:53:22.595000+00:00</td>\n",
       "      <td>2024-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>661f98400b743e7790933c6c</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>65cdb847e4b0910621e3ee69</td>\n",
       "      <td>under review</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-17 09:37:04.979000+00:00</td>\n",
       "      <td>2024-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661f92fcc186d0624cf5f1f4</td>\n",
       "      <td>65c5d287e4b0bea88872e63b</td>\n",
       "      <td>65cdb848e4b0910621e3ee6d</td>\n",
       "      <td>under review</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-04-17 09:14:36.791000+00:00</td>\n",
       "      <td>2024-04-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                  courseId  \\\n",
       "0  661cd6bcf179b74c0b33e51f  65c5d287e4b0bea88872e63b   \n",
       "1  661cf17f350de60f684a7d62  65c5d287e4b0bea88872e63b   \n",
       "2  6615566215d8d561ecaa108a  65c5d287e4b0bea88872e63b   \n",
       "3  661f98400b743e7790933c6c  65c5d287e4b0bea88872e63b   \n",
       "4  661f92fcc186d0624cf5f1f4  65c5d287e4b0bea88872e63b   \n",
       "\n",
       "                     userId        status  data/0/date/date  data/0/date/day  \\\n",
       "0  63b6dbd1e4b04d78f40b0ad0      rejected                15                1   \n",
       "1  63b6dbf1e4b04d78f40b0c00  under review                15                1   \n",
       "2  63b6dbf4e4b04d78f40b0c2e  under review                 9                2   \n",
       "3  65cdb847e4b0910621e3ee69  under review                17                3   \n",
       "4  65cdb848e4b0910621e3ee6d  under review                17                3   \n",
       "\n",
       "   data/0/date/hours  data/0/date/minutes  data/0/date/month  \\\n",
       "0                  7                   26                  3   \n",
       "1                  9                   21                  3   \n",
       "2                 14                   53                  3   \n",
       "3                  9                   37                  3   \n",
       "4                  9                   14                  3   \n",
       "\n",
       "   data/0/date/seconds  ...  data/7/date/time  data/7/date/timezoneOffset  \\\n",
       "0                   52  ...               NaN                         NaN   \n",
       "1                    3  ...               NaN                         NaN   \n",
       "2                   22  ...               NaN                         NaN   \n",
       "3                    4  ...               NaN                         NaN   \n",
       "4                   36  ...               NaN                         NaN   \n",
       "\n",
       "   data/7/date/year data/7/date/$date data/7/status data/7/message  \\\n",
       "0               NaN               NaN           NaN            NaN   \n",
       "1               NaN               NaN           NaN            NaN   \n",
       "2               NaN               NaN           NaN            NaN   \n",
       "3               NaN               NaN           NaN            NaN   \n",
       "4               NaN               NaN           NaN            NaN   \n",
       "\n",
       "   data/7/adminId data/4/notes                 Latest_Submission  \\\n",
       "0             NaN          NaN  2024-04-16 11:12:11.965000+00:00   \n",
       "1             NaN          NaN  2024-04-15 09:21:03.916000+00:00   \n",
       "2             NaN          NaN  2024-04-09 14:53:22.595000+00:00   \n",
       "3             NaN          NaN  2024-04-17 09:37:04.979000+00:00   \n",
       "4             NaN          NaN  2024-04-17 09:14:36.791000+00:00   \n",
       "\n",
       "   Latest_Submission_split  \n",
       "0               2024-04-16  \n",
       "1               2024-04-15  \n",
       "2               2024-04-09  \n",
       "3               2024-04-17  \n",
       "4               2024-04-17  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "050d63d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['reviewed', 'rejected', 'under review'], dtype=object)"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a1712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "71756110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For preparing for Assignment - DataFrame 1 - Date 2024-04-17:\n",
      "{'under review': 3}\n",
      "For preparing for Assignment - DataFrame 2 - Date 2024-04-17:\n",
      "{'under review': 46, 'rejected': 22, 'reviewed': 4}\n",
      "For preparing for Assignment - DataFrame 3 - Date 2024-04-17:\n",
      "{'under review': 9}\n",
      "For preparing for Assignment - DataFrame 4 - Date 2024-04-17:\n",
      "{}\n",
      "For preparing for Assignment - DataFrame 5 - Date 2024-04-17:\n",
      "{}\n",
      "For preparing for Assignment - DataFrame 6 - Date 2024-04-17:\n",
      "{}\n",
      "For preparing for Assignment - DataFrame 7 - Date 2024-04-17:\n",
      "{'under review': 1}\n",
      "For preparing for Assignment - DataFrame 8 - Date 2024-04-17:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the 'dataframes' list, assuming it contains the relevant information about the CSV files\n",
    "\n",
    "# Define the number of CSV files based on the length of the 'dataframes' list\n",
    "number_of_files = len(dataframe_names)\n",
    "\n",
    "# Determine the Previous Dates to the Latest Dates in the 'Latest_Submission_split' Column\n",
    "latest_dates = []\n",
    "\n",
    "for i in range(1, number_of_files + 1):\n",
    "    file_path = f'updated_file_{i}.csv'  \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    if 'Latest_Submission_split' in df.columns:\n",
    "        latest_date = pd.to_datetime(df['Latest_Submission_split']).max().strftime('%Y-%m-%d')\n",
    "        previous_date = (pd.to_datetime(df['Latest_Submission_split']).max() - pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "        previous_date_to_date = (pd.to_datetime(df['Latest_Submission_split']).max() - pd.DateOffset(days=2)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        latest_dates.append(previous_date)\n",
    "        latest_dates.append(previous_date_to_date)\n",
    "        \n",
    "    else:\n",
    "        print(f\"'Latest_Submission_split' column does not exist in DataFrame {i}\")\n",
    "\n",
    "sorted_target_dates = sorted(list(set(latest_dates)))\n",
    "target_dates = sorted_target_dates[-1:]\n",
    "\n",
    "################################################\n",
    "#Use this to type dates yourself else it will take the date previous to the latest today's date\n",
    "#target_dates=['2024-04-05','2024-04-06','2024-04-08','2024-04-09','2024-04-10','2024-04-11','2024-04-12']\n",
    "##################################################\n",
    "\n",
    "\n",
    "# Process Status Counts based on Specific Target Dates for Multiple CSV Files\n",
    "status_counts = []\n",
    "\n",
    "for i in range(1, number_of_files + 1):  \n",
    "    file_path = f'updated_file_{i}.csv'  \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    status_counts_for_date = []  \n",
    "\n",
    "    for target_date in target_dates:\n",
    "        if 'Latest_Submission_split' in df.columns:\n",
    "            filtered_data = df[pd.to_datetime(df['Latest_Submission_split']).dt.date == pd.to_datetime(target_date).date()]\n",
    "            status_count = filtered_data['status'].value_counts().to_dict()\n",
    "            status_counts_for_date.append(status_count)\n",
    "            print(f\"For preparing for Assignment - DataFrame {i} - Date {target_date}:\")\n",
    "            print(status_count)\n",
    "        else:\n",
    "            print(f\"'Latest_Submission_split' column does not exist in DataFrame {i}\")\n",
    "\n",
    "    status_counts.append(status_counts_for_date)\n",
    "\n",
    "# 'status_counts' now contains the status counts for each DataFrame for each target date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64b89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "c5401453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Assignment_file_names</th>\n",
       "      <th>Date</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>24h_New_Submits</th>\n",
       "      <th>Rejected</th>\n",
       "      <th>Total_checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Assignment_Assignment_CAP Classwork.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Assignment_Assignment_CV_ Resume.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Assignment_Assignment_Full CAP - GoalA+B.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Assignment_Assignment_SMART goal.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DataFrame                         Assignment_file_names        Date  \\\n",
       "0          1       Assignment_Assignment_CAP Classwork.csv  2024-04-17   \n",
       "1          2          Assignment_Assignment_CV_ Resume.csv  2024-04-17   \n",
       "2          3  Assignment_Assignment_Full CAP - GoalA+B.csv  2024-04-17   \n",
       "3          7          Assignment_Assignment_SMART goal.csv  2024-04-17   \n",
       "\n",
       "   Accepted  24h_New_Submits  Rejected  Total_checked  \n",
       "0         0                3         0              0  \n",
       "1         4               46        22             26  \n",
       "2         0                9         0              0  \n",
       "3         0                1         0              0  "
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to store the tabular data\n",
    "tabular_data = []\n",
    "\n",
    "# Function to calculate the count of items under review\n",
    "def get_under_review_count(status_count_dict):\n",
    "    under_review_count = status_count_dict.get('under review', 0)  # Assuming 'under_review' is the key for under review counts\n",
    "    return under_review_count\n",
    "\n",
    "# Iterate through each DataFrame and target date\n",
    "for i in range(len(status_counts)):\n",
    "    for j in range(len(target_dates)):\n",
    "        if status_counts[i][j]:  # Checking if status count exists for the target date\n",
    "            reviewed_count = status_counts[i][j].get('reviewed', 0)\n",
    "            under_review_count = get_under_review_count(status_counts[i][j])\n",
    "            rejected_count = status_counts[i][j].get('rejected', 0)\n",
    "            tabular_data.append({\n",
    "                'DataFrame': i+1,\n",
    "                'Assignment_file_names':b[i],\n",
    "                'Date': target_dates[j],\n",
    "                'Accepted': reviewed_count,\n",
    "                '24h_New_Submits': under_review_count,\n",
    "                'Rejected': rejected_count,\n",
    "                'Total_checked':(reviewed_count+rejected_count)\n",
    "\n",
    "                \n",
    "            })\n",
    "\n",
    "# Create a DataFrame from the tabular data\n",
    "tabular_df = pd.DataFrame(tabular_data)\n",
    "\n",
    "# Display the tabular DataFrame\n",
    "tabular_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809d9cc",
   "metadata": {},
   "source": [
    "The total number of Assignments checked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "5599d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Assignments that are checked is 26\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Assignments that are checked is\",tabular_df['Total_checked'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "17e2dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Assignments that are Submitted is 59\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Assignments that are Submitted is\",tabular_df['24h_New_Submits'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "13c854bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df.to_excel(\"C:/Users/User/Downloads/Daily update in count of Assignment submissions.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "eed01434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Assignment_file_names</th>\n",
       "      <th>Date</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>24h_New_Submits</th>\n",
       "      <th>Rejected</th>\n",
       "      <th>Total_checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Assignment_Assignment_CAP Classwork.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Assignment_Assignment_CV_ Resume.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Assignment_Assignment_Full CAP - GoalA+B.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Assignment_Assignment_SMART goal.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DataFrame                         Assignment_file_names        Date  \\\n",
       "0          1       Assignment_Assignment_CAP Classwork.csv  2024-04-17   \n",
       "1          2          Assignment_Assignment_CV_ Resume.csv  2024-04-17   \n",
       "2          3  Assignment_Assignment_Full CAP - GoalA+B.csv  2024-04-17   \n",
       "3          7          Assignment_Assignment_SMART goal.csv  2024-04-17   \n",
       "\n",
       "   Accepted  24h_New_Submits  Rejected  Total_checked  \n",
       "0         0                3         0              0  \n",
       "1         4               46        22             26  \n",
       "2         0                9         0              0  \n",
       "3         0                1         0              0  "
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_excel(\"C:/Users/User/Downloads/Daily update in count of Assignment submissions.xlsx\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b5256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "2cfebdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the existing Excel file into a DataFrame\n",
    "existing_data = pd.read_excel(\"C:/Users/User/Downloads/Daily update in count of Assignment submissions.xlsx\")\n",
    "\n",
    "# Load the new data from the attached file into another DataFrame\n",
    "new_data = pd.read_excel(\"C:/Users/User/Downloads/new file.xlsx\")\n",
    "\n",
    "# Concatenate the new data below the existing data\n",
    "combined_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "\n",
    "# Write the combined data back to the Excel file\n",
    "combined_data.to_excel(\"C:/Users/User/Downloads/new file.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "aa229fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>Assignment_file_names</th>\n",
       "      <th>Date</th>\n",
       "      <th>Accepted</th>\n",
       "      <th>24h_New_Submits</th>\n",
       "      <th>Rejected</th>\n",
       "      <th>Total_checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Assignment_Assignment_CAP Classwork.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Assignment_Assignment_CV_ Resume.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Assignment_Assignment_Full CAP - GoalA+B.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Assignment_Assignment_SMART goal.csv</td>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Assignment_Assignment_CV_ Resume.csv</td>\n",
       "      <td>2024-04-16</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5</td>\n",
       "      <td>Assignment_Assignment_CAP-Goals_Strategy.csv</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>Assignment_Assignment_Long term dreams and sho...</td>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>Assignment_Assignment_Preparing for PG_Masters...</td>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>138</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3</td>\n",
       "      <td>Assignment_Assignment_SMART goal.csv</td>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>Assignment_Assignment_SWOT.csv</td>\n",
       "      <td>2024-03-27</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DataFrame                              Assignment_file_names        Date  \\\n",
       "0           1            Assignment_Assignment_CAP Classwork.csv  2024-04-17   \n",
       "1           2               Assignment_Assignment_CV_ Resume.csv  2024-04-17   \n",
       "2           3       Assignment_Assignment_Full CAP - GoalA+B.csv  2024-04-17   \n",
       "3           7               Assignment_Assignment_SMART goal.csv  2024-04-17   \n",
       "4           2               Assignment_Assignment_CV_ Resume.csv  2024-04-16   \n",
       "..        ...                                                ...         ...   \n",
       "72          5       Assignment_Assignment_CAP-Goals_Strategy.csv  2024-03-31   \n",
       "73          1  Assignment_Assignment_Long term dreams and sho...  2024-03-27   \n",
       "74          2  Assignment_Assignment_Preparing for PG_Masters...  2024-03-27   \n",
       "75          3               Assignment_Assignment_SMART goal.csv  2024-03-27   \n",
       "76          4                     Assignment_Assignment_SWOT.csv  2024-03-27   \n",
       "\n",
       "    Accepted  24h_New_Submits  Rejected  Total_checked  \n",
       "0          0                3         0              0  \n",
       "1          4               46        22             26  \n",
       "2          0                9         0              0  \n",
       "3          0                1         0              0  \n",
       "4          1                6        38             39  \n",
       "..       ...              ...       ...            ...  \n",
       "72         0                5         0              0  \n",
       "73         0               18         0              0  \n",
       "74       138               25        49            187  \n",
       "75         0               24         0              0  \n",
       "76         2               14         0              2  \n",
       "\n",
       "[77 rows x 7 columns]"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93507574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fd3daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18611a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
